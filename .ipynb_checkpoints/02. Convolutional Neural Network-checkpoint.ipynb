{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Same as Ordinary NN because these are also made of Neurons\n",
    "- These Neurons can learn biases and weights\n",
    "- Data is fed into Ordinary NN after converting to 1-D array\n",
    "- If data is Image than it will be an issue\n",
    "- CNN takes the 2-D structure of the Images while processing them\n",
    "\n",
    "<img src=\"Image/cnn1.png\" width=\"400\" />\n",
    "\n",
    "$CONVOLUTION \\longrightarrow MAX POOLING \\longrightarrow FLATTENING \\longrightarrow FULL CONNECTION$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:CONVOLUTION\n",
    "- Identify features and put it in feature map while preverving special relation between pixels\n",
    "<img src=\"Image/convolution.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1(a):\n",
    "We create many Feature Maps by taking different Feature Detector to obtain our first convolution layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: MAX POOLING\n",
    "- If same image be rotated or strectched or shrinked, Neural Network should be able to recognize it.\n",
    "- preserving the feature\n",
    "- reducing size\n",
    "- reducing parameter so preventing over-fitting\n",
    "\n",
    "<img src=\"Image/max.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: FLATTENING\n",
    "<img src=\"Image/flattening.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Fully Connected Layer\n",
    "- in Artificial NN its hidden layer\n",
    "- in ANN we have one output - regression problem\n",
    "- in CNN we have multiple output - classification problem\n",
    "\n",
    "<img src=\"Image/full_layer.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation\n",
    "- Function - prevent overfitting by providing more dataset to train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train CNN , we need lot of images. It create many batches. In each batch it create images from existing images by random transformation(flipping, rotating, shifting, etc) after selecting images randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras Function  \n",
    "https://keras.io/api/preprocessing/image/  \n",
    "\n",
    "<img src=\"Image/image_aug.JPG\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rescale = changes value of pixels to be between 0 and 1  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CCN for 3 Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Network(CNN)\n",
    "# Dataset - Kaggle (https://www.kaggle.com/andrewmvd/animal-faces)\n",
    "# importing the libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# S1 - Convolution\n",
    "# 32 features map of size 3*3\n",
    "# As all image size is not same, so define input to changeall image to same size (64, 64, 3) - color image\n",
    "# tensorflow order (64,64,3), theano order (3, 64, 64)\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape = (32, 32, 3), activation = 'relu'))\n",
    "\n",
    "# S2 - Max Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Increasing the accuracy by adding a second convolutional layer\n",
    "classifier.add(Convolution2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# S3 - flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# S4 - Full Connection\n",
    "# can add layer to increase accuracy\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "#for 2 output sigmoid, for more than two softmax\n",
    "classifier.add(Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "# Compile phase, for 2 loss=binary_crossentropy, for more than 2 cross_entropy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Part 2 - Fit images in the CNN\n",
    "#Refer- https://keras.io/api/preprocessing/image/\n",
    "# Geomatrical transformation- shear, zoom, horizontal flip\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory('dataset/train',\n",
    "                                                 target_size = (32, 32),\n",
    "                                                 batch_size = 64,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_data = test_datagen.flow_from_directory('dataset/val',\n",
    "                                            target_size = (32, 32),\n",
    "                                            batch_size = 64,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "classifier.fit_generator(train_data,\n",
    "                         steps_per_epoch = 200,\n",
    "                         epochs = 20,\n",
    "                         validation_data = test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN for Binary Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional Neural Network(CNN)\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# S1 - Convolution\n",
    "# 32 features map of size 3*3\n",
    "# As all image size is not same, so define input to changeall image to same size (64, 64, 3) - color image\n",
    "# tensorflow order (64,64,3), theano order (3, 64, 64)\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape = (32, 32, 3), activation = 'relu'))\n",
    "\n",
    "# S2 - Max Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Increasing the accuracy by adding a second convolutional layer\n",
    "classifier.add(Convolution2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# S3 - flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# S4 - Full Connection\n",
    "# can add layer to increase accuracy\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "#for 2 output sigmoid, for more than two softmax\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compile phase, for 2 loss=binary_crossentropy, for more than 2 cross_entropy\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Part 2 - Fit images in the CNN\n",
    "#Refer- https://keras.io/api/preprocessing/image/\n",
    "# Geomatrical transformation- shear, zoom, horizontal flip\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory('dataset_2/train',\n",
    "                                                 target_size = (32, 32),\n",
    "                                                 batch_size = 64,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_data = test_datagen.flow_from_directory('dataset_2/val',\n",
    "                                            target_size = (32, 32),\n",
    "                                            batch_size = 64,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "classifier.fit_generator(train_data,\n",
    "                         steps_per_epoch = 200,\n",
    "                         epochs = 20,\n",
    "                         validation_data = test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
